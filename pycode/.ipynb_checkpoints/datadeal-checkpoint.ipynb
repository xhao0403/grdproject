{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理流程\n",
    "1. 数据读入\n",
    "2. 数据清洗\n",
    "3. 数据无量纲化处理\n",
    "4. 特征选择\n",
    "5. 特征提取\n",
    "6. 聚类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将数据文件处理成电脑可处理的小规模的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'newdata/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-39c5709696fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 从文件夹'newdata/'中读取数据文件\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfiledir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'newdata/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiledir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'newdata/'"
     ]
    }
   ],
   "source": [
    "# 从文件夹'newdata/'中读取数据文件\n",
    "filedir = 'newdata/'\n",
    "files = os.listdir(filedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 10000 # 每个文件中读取前nrows行数据\n",
    "alldata = pd.DataFrame() #新建空的DataFrame\n",
    "for f in files: # 循环读入数据，加入到新建的DataFrame中\n",
    "    tdata = pd.read_csv(filedir + f, nrows=nrows)\n",
    "    print('read ' + str(tdata.shape[0]) + ' rows from' + f)\n",
    "    alldata = alldata.append(tdata, ignore_index=True)\n",
    "    #alldata = alldata.append(tdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = alldata.columns\n",
    "alldata = alldata.drop(cols[0:2],axis = 1) # 删除两列必然没用的数据\n",
    "alldata = alldata.dropna(how='any') # 删除含有nan值的数据\n",
    "alldata.reset_index(inplace=True, drop=True) # 重置index\n",
    "alldata\n",
    "# 36079 rows × 87 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = set(alldata[' Label'])\n",
    "labels = []\n",
    "for l in L:\n",
    "    labels.append(l)\n",
    "labels\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata.dropna(how='any',inplace=True) # 再次删除含有空值的行\n",
    "\n",
    "# 删除非数值型数据，这些数据暂时不用于聚类处理，但不代表这些数据没用\n",
    "dropset = ['Flow ID', ' Source IP', ' Source Port',\n",
    "       ' Destination IP', ' Destination Port', ' Protocol', ' Timestamp',\n",
    "           ' Fwd Header Length.1', 'SimillarHTTP', ' Inbound']\n",
    "# 删除含有大量负数的列\n",
    "drop_nega = [' Fwd Header Length', 'Init_Win_bytes_forward',\n",
    "       ' Init_Win_bytes_backward', ' act_data_pkt_fwd',\n",
    "       ' min_seg_size_forward']\n",
    "alldata.drop(dropset, axis=1,inplace=True)\n",
    "alldata.drop(drop_nega, axis=1,inplace=True)\n",
    "cols = alldata.columns\n",
    "# len(dropset),cols.size\n",
    "\n",
    "# 将labels替代成数值型值\n",
    "for i in range(len(labels)):\n",
    "    alldata.replace(to_replace =labels[i], value = i, inplace = True)\n",
    "    print(labels[i] + ' was replace to ' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除数据中inf的值\n",
    "idx_tuple = np.where(alldata.max(axis=1).values == np.inf)\n",
    "idx = list(idx_tuple[0])\n",
    "alldata.drop(axis=0, index = idx, inplace = True)\n",
    "alldata.reset_index(inplace=True, drop=True)\n",
    "# 删除数据中含负数的数据条数\n",
    "idx_tuple = np.where(alldata.min(axis=1).values < 0)\n",
    "idx = list(idx_tuple[0])\n",
    "alldata.drop(axis=0, index = idx, inplace = True)\n",
    "alldata.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分数据X-Y\n",
    "Y = alldata[' Label']\n",
    "X = alldata.drop([' Label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将pandas数据转成numpy array\n",
    "X = X.values\n",
    "Y = Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据无量纲化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 采用两种不同的标准化方式\n",
    "#MaxAbs标准化\n",
    "#建立MinMaxScaler对象\n",
    "maxabs = preprocessing.MaxAbsScaler()\n",
    "# 标准化处理\n",
    "data_maxabs = maxabs.fit_transform(X)\n",
    "\n",
    "#zscore标准化\n",
    "zscore = preprocessing.StandardScaler()\n",
    "#zscore标准化\n",
    "X_zscore = zscore.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 递归特征消除法\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X_new = RFE(estimator=LogisticRegression(), n_features_to_select=10).fit_transform(data_maxabs, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_maxabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_new = SelectKBest(lambda X, Y: array(list(map(lambda x:pearsonr(x, Y), X.o))).T, k=30).fit_transform(data_maxabs, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "estimator = PCA(n_components=8)\n",
    "pca_X_train = estimator.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 普通 Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(KMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 5, init='k-means++', n_init=50).fit(pca_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Y)): # 指标筛选之后好多了\n",
    "    print(y_[i], Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:grdenv]",
   "language": "python",
   "name": "conda-env-grdenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
