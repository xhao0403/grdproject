{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack Dectection For Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy.io as io\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from numpy import array\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import math\n",
    "from scipy.linalg import expm,logm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_path = '/mnt/hgfs/linuxfile/train_npy_set/train_X.npy'\n",
    "train_Y_path = '/mnt/hgfs/linuxfile/train_npy_set/train_Y.npy'\n",
    "test_X_path = '/mnt/hgfs/linuxfile/test_npy_set/test_X.npy'\n",
    "test_Y_path = '/mnt/hgfs/linuxfile/test_npy_set/test_Y.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.load(train_X_path)\n",
    "train_Y = np.load(train_Y_path)\n",
    "test_X = np.load(test_X_path)\n",
    "test_Y = np.load(test_Y_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 极限树\n",
    "# Extra_model = ExtraTreesClassifier(random_state = 1).fit(train_X,train_Y)\n",
    "\n",
    "# test_Y_hat = Extra_model.predict(test_X)\n",
    "\n",
    "# print(accuracy_score(test_Y, test_Y_hat))\n",
    "# print(precision_score(test_Y, test_Y_hat,average='micro'))\n",
    "# print(recall_score(test_Y, test_Y_hat,average='micro'))\n",
    "# print(f1_score(test_Y, test_Y_hat,average='micro'))\n",
    "# print(classification_report(test_Y, test_Y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## 随机森林\n",
    "# RandomForest_model = RandomForestClassifier().fit(train_X,train_Y)\n",
    "\n",
    "# test_Y_hat = RandomForest_model.predict(test_X)\n",
    "\n",
    "# print(accuracy_score(test_Y, test_Y_hat))\n",
    "# print(precision_score(test_Y, test_Y_hat,average='micro'))\n",
    "# print(recall_score(test_Y, test_Y_hat,average='micro'))\n",
    "# print(f1_score(test_Y, test_Y_hat,average='micro'))\n",
    "# print(classification_report(test_Y, test_Y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## GBDT\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# GBDT_model = GradientBoostingClassifier().fit(train_X, train_Y)\n",
    "# test_Y_hat = GBDT_model.predict(test_X)\n",
    "\n",
    "# print(accuracy_score(test_Y, test_Y_hat))\n",
    "# print(precision_score(test_Y, test_Y_hat,average='micro'))\n",
    "# print(recall_score(test_Y, test_Y_hat,average='micro'))\n",
    "# print(f1_score(test_Y, test_Y_hat,average='micro'))\n",
    "# print(classification_report(test_Y, test_Y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## SVM\n",
    "# from sklearn.svm import SVC\n",
    "# svm_model = SVC(kernel='linear', C = 1.0, random_state=1).fit(train_X, train_Y)\n",
    "\n",
    "# test_Y_hat = svm_model.predict(test_X)\n",
    "\n",
    "# print(accuracy_score(test_Y, test_Y_hat))\n",
    "# print(precision_score(test_Y, test_Y_hat,average='micro'))\n",
    "# print(recall_score(test_Y, test_Y_hat,average='micro'))\n",
    "# print(f1_score(test_Y, test_Y_hat,average='micro'))\n",
    "# print(classification_report(test_Y, test_Y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5709335528083849\n",
      "0.5709335528083849\n",
      "0.5709335528083849\n",
      "0.5709335528083849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.01      0.02     48389\n",
      "           1       0.84      0.89      0.86     43546\n",
      "           2       0.49      0.45      0.47     49221\n",
      "           3       0.12      0.02      0.04     48560\n",
      "           4       0.04      0.00      0.00     49340\n",
      "           5       0.31      0.94      0.47     48595\n",
      "           6       0.33      0.95      0.49     49897\n",
      "           7       0.99      0.84      0.91    111271\n",
      "           8       0.92      0.99      0.95     48395\n",
      "           9       0.59      0.00      0.00     49063\n",
      "          10       0.86      0.87      0.86     49083\n",
      "\n",
      "    accuracy                           0.57    595360\n",
      "   macro avg       0.51      0.54      0.46    595360\n",
      "weighted avg       0.56      0.57      0.50    595360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "AdaBoost_model = AdaBoostClassifier().fit(train_X, train_Y)\n",
    "test_Y_hat = AdaBoost_model.predict(test_X)\n",
    "\n",
    "print(accuracy_score(test_Y, test_Y_hat))\n",
    "print(precision_score(test_Y, test_Y_hat,average='micro'))\n",
    "print(recall_score(test_Y, test_Y_hat,average='micro'))\n",
    "print(f1_score(test_Y, test_Y_hat,average='micro'))\n",
    "print(classification_report(test_Y, test_Y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4950063826928245\n",
      "0.4950063826928245\n",
      "0.4950063826928245\n",
      "0.4950063826928245\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.07      0.05     48389\n",
      "           1       0.96      0.98      0.97     43546\n",
      "           2       0.03      0.02      0.02     49221\n",
      "           3       0.00      0.00      0.00     48560\n",
      "           4       0.39      0.65      0.49     49340\n",
      "           5       0.41      0.77      0.53     48595\n",
      "           6       0.61      0.68      0.65     49897\n",
      "           7       0.99      0.98      0.98    111271\n",
      "           8       0.11      0.01      0.02     48395\n",
      "           9       0.42      0.71      0.53     49063\n",
      "          10       0.00      0.00      0.00     49083\n",
      "\n",
      "    accuracy                           0.50    595360\n",
      "   macro avg       0.36      0.44      0.39    595360\n",
      "weighted avg       0.42      0.50      0.45    595360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 决策树\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DecisionTree_model = DecisionTreeClassifier(random_state=3).fit(train_X, train_Y)\n",
    "test_Y_hat = DecisionTree_model.predict(test_X)\n",
    "\n",
    "print(accuracy_score(test_Y, test_Y_hat))\n",
    "print(precision_score(test_Y, test_Y_hat,average='micro'))\n",
    "print(recall_score(test_Y, test_Y_hat,average='micro'))\n",
    "print(f1_score(test_Y, test_Y_hat,average='micro'))\n",
    "print(classification_report(test_Y, test_Y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(DecisionTree_model.class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.86060493e-02, 5.05735960e-02, 7.27245174e-02, 6.14383542e-03,\n",
       "       3.76238476e-03, 1.46703730e-04, 7.91534719e-04, 4.36989871e-02,\n",
       "       1.32066627e-03, 7.74753313e-03, 6.79833351e-03, 2.05192890e-02,\n",
       "       7.48240024e-03, 1.30187105e-02, 6.55314981e-03, 7.85731603e-04,\n",
       "       1.28457554e-01, 2.47559789e-01, 2.19441283e-01, 9.85733815e-04,\n",
       "       1.56584562e-04, 2.28780516e-03, 1.35275949e-01, 1.14543761e-03,\n",
       "       4.05509216e-04, 3.61093239e-03])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTree_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuhao/miniconda3/envs/grdenv/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6545333915614082\n",
      "0.6545333915614082\n",
      "0.6545333915614082\n",
      "0.6545333915614082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.02      0.03     48389\n",
      "           1       0.75      1.00      0.86     43546\n",
      "           2       0.46      0.54      0.50     49221\n",
      "           3       1.00      0.54      0.70     48560\n",
      "           4       0.11      0.00      0.00     49340\n",
      "           5       0.39      0.87      0.54     48595\n",
      "           6       0.53      0.73      0.61     49897\n",
      "           7       1.00      0.81      0.89    111271\n",
      "           8       0.81      0.99      0.89     48395\n",
      "           9       0.45      0.63      0.53     49063\n",
      "          10       0.93      0.93      0.93     49083\n",
      "\n",
      "    accuracy                           0.65    595360\n",
      "   macro avg       0.59      0.64      0.59    595360\n",
      "weighted avg       0.63      0.65      0.62    595360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 逻辑回归\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression(penalty='l2').fit(train_X, train_Y)\n",
    "test_Y_hat = lr_model.predict(test_X)\n",
    "print(accuracy_score(test_Y, test_Y_hat))\n",
    "print(precision_score(test_Y, test_Y_hat,average='micro'))\n",
    "print(recall_score(test_Y, test_Y_hat,average='micro'))\n",
    "print(f1_score(test_Y, test_Y_hat,average='micro'))\n",
    "print(classification_report(test_Y, test_Y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5776857699543133\n",
      "0.5776857699543133\n",
      "0.5776857699543133\n",
      "0.5776857699543133\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.62      0.35     48389\n",
      "           1       0.97      1.00      0.98     43546\n",
      "           2       0.38      0.17      0.23     49221\n",
      "           3       0.99      0.54      0.70     48560\n",
      "           4       0.49      0.32      0.39     49340\n",
      "           5       0.37      0.75      0.50     48595\n",
      "           6       0.69      0.20      0.31     49897\n",
      "           7       1.00      0.99      0.99    111271\n",
      "           8       0.93      0.08      0.15     48395\n",
      "           9       0.27      0.34      0.30     49063\n",
      "          10       0.76      0.88      0.81     49083\n",
      "\n",
      "    accuracy                           0.58    595360\n",
      "   macro avg       0.64      0.54      0.52    595360\n",
      "weighted avg       0.68      0.58      0.56    595360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "knn_model = KNeighborsClassifier(n_neighbors=7).fit(train_X, train_Y)\n",
    "test_Y_hat = knn_model.predict(test_X)\n",
    "print(accuracy_score(test_Y, test_Y_hat))\n",
    "print(precision_score(test_Y, test_Y_hat,average='micro'))\n",
    "print(recall_score(test_Y, test_Y_hat,average='micro'))\n",
    "print(f1_score(test_Y, test_Y_hat,average='micro'))\n",
    "print(classification_report(test_Y, test_Y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uniform'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:grdenv]",
   "language": "python",
   "name": "conda-env-grdenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
